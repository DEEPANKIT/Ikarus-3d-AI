{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ikarus 3D Furniture Dataset - Comprehensive Data Analysis\n",
        "\n",
        "## Overview\n",
        "This notebook provides a comprehensive exploratory data analysis (EDA) of the Ikarus 3D furniture product dataset. We'll analyze product characteristics, pricing patterns, brand distribution, and text content to gain insights that will inform our ML recommendation system.\n",
        "\n",
        "## Dataset Information\n",
        "- **Source**: Ikarus 3D furniture product catalog\n",
        "- **Size**: 312 products\n",
        "- **Features**: title, brand, description, price, categories, images, material, country_of_origin, etc.\n",
        "- **Purpose**: Build ML-driven product recommendation system\n",
        "\n",
        "## Analysis Objectives\n",
        "1. **Data Quality Assessment**: Identify missing values, duplicates, and data inconsistencies\n",
        "2. **Price Analysis**: Understand pricing patterns and distribution\n",
        "3. **Category Analysis**: Explore product categorization and diversity\n",
        "4. **Brand Analysis**: Analyze brand distribution and market presence\n",
        "5. **Text Analysis**: Examine product descriptions and titles\n",
        "6. **Image Analysis**: Assess image availability and quality\n",
        "7. **Geographic Analysis**: Understand product origins\n",
        "8. **Material Analysis**: Explore material composition patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for data analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import json\n",
        "from collections import Counter\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "# Configure plotting and logging\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up logging for analysis tracking\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"✅ Libraries imported successfully\")\n",
        "print(\"📊 Ready to begin comprehensive data analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Ikarus 3D furniture dataset\n",
        "# This dataset contains 312 furniture products with various attributes\n",
        "\n",
        "data_path = Path(\"../data/raw/intern_data_ikarus.csv\")\n",
        "\n",
        "try:\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.read_csv(data_path)\n",
        "    \n",
        "    # Display basic information about the dataset\n",
        "    print(\"🎯 DATASET LOADED SUCCESSFULLY\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"📊 Dataset Shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
        "    print(f\"💾 Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(\"\\n📋 Column Names:\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"  {i:2d}. {col}\")\n",
        "    \n",
        "    # Display first few rows to understand the data structure\n",
        "    print(\"\\n🔍 First 3 rows of the dataset:\")\n",
        "    print(df.head(3).to_string())\n",
        "    \n",
        "    logger.info(f\"Dataset loaded successfully: {df.shape[0]} products, {df.shape[1]} features\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading dataset: {e}\")\n",
        "    logger.error(f\"Failed to load dataset: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Quality Assessment\n",
        "\n",
        "Before diving into analysis, we need to understand the quality and completeness of our dataset. This section will:\n",
        "- Check for missing values across all columns\n",
        "- Identify duplicate records\n",
        "- Examine data types and potential inconsistencies\n",
        "- Assess overall data completeness\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Assessment\n",
        "# This analysis helps us understand data completeness and identify potential issues\n",
        "\n",
        "print(\"🔍 DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Check data types\n",
        "print(\"📊 Data Types:\")\n",
        "print(df.dtypes)\n",
        "print()\n",
        "\n",
        "# 2. Check for missing values\n",
        "print(\"❌ Missing Values Analysis:\")\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percentage = (missing_data / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Column': missing_data.index,\n",
        "    'Missing_Count': missing_data.values,\n",
        "    'Missing_Percentage': missing_percentage.values\n",
        "}).sort_values('Missing_Percentage', ascending=False)\n",
        "\n",
        "print(missing_df.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# 3. Check for duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"🔄 Duplicate Records: {duplicates} ({duplicates/len(df)*100:.2f}%)\")\n",
        "print()\n",
        "\n",
        "# 4. Basic statistics for numeric columns\n",
        "print(\"📈 Basic Statistics for Numeric Columns:\")\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_cols) > 0:\n",
        "    print(df[numeric_cols].describe())\n",
        "else:\n",
        "    print(\"No numeric columns found\")\n",
        "print()\n",
        "\n",
        "# 5. Memory usage by column\n",
        "print(\"💾 Memory Usage by Column (MB):\")\n",
        "memory_usage = df.memory_usage(deep=True) / 1024**2\n",
        "for col, usage in memory_usage.items():\n",
        "    print(f\"  {col}: {usage:.3f} MB\")\n",
        "\n",
        "logger.info(f\"Data quality assessment completed. Missing values: {missing_data.sum()}, Duplicates: {duplicates}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Price Analysis\n",
        "\n",
        "Understanding pricing patterns is crucial for our recommendation system. We'll analyze:\n",
        "- Price distribution and statistics\n",
        "- Price ranges and categories\n",
        "- Outliers and unusual pricing patterns\n",
        "- Price correlation with other features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Price Analysis\n",
        "# Clean and analyze pricing data to understand market patterns\n",
        "\n",
        "print(\"💰 PRICE ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Clean price data - remove $ symbol and convert to float\n",
        "df['price_clean'] = df['price'].str.replace('$', '').astype(float)\n",
        "\n",
        "# Calculate price statistics\n",
        "price_stats = {\n",
        "    'count': df['price_clean'].count(),\n",
        "    'mean': df['price_clean'].mean(),\n",
        "    'median': df['price_clean'].median(),\n",
        "    'std': df['price_clean'].std(),\n",
        "    'min': df['price_clean'].min(),\n",
        "    'max': df['price_clean'].max(),\n",
        "    'q25': df['price_clean'].quantile(0.25),\n",
        "    'q75': df['price_clean'].quantile(0.75)\n",
        "}\n",
        "\n",
        "print(\"📊 Price Statistics:\")\n",
        "for stat, value in price_stats.items():\n",
        "    print(f\"  {stat.upper()}: ${value:.2f}\")\n",
        "print()\n",
        "\n",
        "# Identify outliers using IQR method\n",
        "Q1 = price_stats['q25']\n",
        "Q3 = price_stats['q75']\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['price_clean'] < lower_bound) | (df['price_clean'] > upper_bound)]\n",
        "print(f\"🔍 Price Outliers (IQR method): {len(outliers)} products ({len(outliers)/len(df)*100:.2f}%)\")\n",
        "print(f\"   Lower bound: ${lower_bound:.2f}, Upper bound: ${upper_bound:.2f}\")\n",
        "print()\n",
        "\n",
        "# Price distribution analysis\n",
        "print(\"📈 Price Distribution by Ranges:\")\n",
        "price_ranges = [\n",
        "    (0, 25, \"$0-25\"),\n",
        "    (25, 50, \"$25-50\"), \n",
        "    (50, 100, \"$50-100\"),\n",
        "    (100, 200, \"$100-200\"),\n",
        "    (200, 500, \"$200-500\"),\n",
        "    (500, float('inf'), \"$500+\")\n",
        "]\n",
        "\n",
        "for min_price, max_price, label in price_ranges:\n",
        "    count = len(df[(df['price_clean'] >= min_price) & (df['price_clean'] < max_price)])\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"  {label}: {count} products ({percentage:.1f}%)\")\n",
        "\n",
        "logger.info(f\"Price analysis completed. Mean: ${price_stats['mean']:.2f}, Median: ${price_stats['median']:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize price distribution\n",
        "# Create comprehensive price analysis visualizations\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('💰 Price Distribution Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Histogram of prices\n",
        "axes[0, 0].hist(df['price_clean'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "axes[0, 0].axvline(df['price_clean'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"price_clean\"].mean():.2f}')\n",
        "axes[0, 0].axvline(df['price_clean'].median(), color='green', linestyle='--', label=f'Median: ${df[\"price_clean\"].median():.2f}')\n",
        "axes[0, 0].set_title('Price Distribution Histogram')\n",
        "axes[0, 0].set_xlabel('Price ($)')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Box plot of prices\n",
        "axes[0, 1].boxplot(df['price_clean'], vert=True)\n",
        "axes[0, 1].set_title('Price Box Plot')\n",
        "axes[0, 1].set_ylabel('Price ($)')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Log-scale histogram (to better see distribution)\n",
        "axes[1, 0].hist(np.log1p(df['price_clean']), bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[1, 0].set_title('Price Distribution (Log Scale)')\n",
        "axes[1, 0].set_xlabel('Log(Price + 1)')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Price range distribution\n",
        "price_range_counts = []\n",
        "price_range_labels = []\n",
        "for min_price, max_price, label in price_ranges:\n",
        "    count = len(df[(df['price_clean'] >= min_price) & (df['price_clean'] < max_price)])\n",
        "    price_range_counts.append(count)\n",
        "    price_range_labels.append(label)\n",
        "\n",
        "axes[1, 1].bar(range(len(price_range_labels)), price_range_counts, color='lightgreen', alpha=0.7)\n",
        "axes[1, 1].set_title('Products by Price Range')\n",
        "axes[1, 1].set_xlabel('Price Range')\n",
        "axes[1, 1].set_ylabel('Number of Products')\n",
        "axes[1, 1].set_xticks(range(len(price_range_labels)))\n",
        "axes[1, 1].set_xticklabels(price_range_labels, rotation=45)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, count in enumerate(price_range_counts):\n",
        "    axes[1, 1].text(i, count + 0.5, str(count), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Price visualization completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Category Analysis\n",
        "\n",
        "Product categories are essential for our recommendation system. We'll analyze:\n",
        "- Category distribution and diversity\n",
        "- Most popular categories\n",
        "- Category hierarchy and relationships\n",
        "- Products with multiple categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Category Analysis\n",
        "# Parse and analyze product categories to understand product diversity\n",
        "\n",
        "print(\"🏷️ CATEGORY ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Parse categories (stored as string representations of lists)\n",
        "all_categories = []\n",
        "category_parsing_errors = 0\n",
        "\n",
        "for idx, cat_str in enumerate(df['categories'].dropna()):\n",
        "    try:\n",
        "        # Use ast.literal_eval for safe evaluation of string representations\n",
        "        import ast\n",
        "        cat_list = ast.literal_eval(cat_str) if isinstance(cat_str, str) else cat_str\n",
        "        if isinstance(cat_list, list):\n",
        "            all_categories.extend(cat_list)\n",
        "        else:\n",
        "            all_categories.append(str(cat_list))\n",
        "    except Exception as e:\n",
        "        category_parsing_errors += 1\n",
        "        # Fallback: treat as single category\n",
        "        all_categories.append(str(cat_str))\n",
        "\n",
        "print(f\"📊 Category Parsing Results:\")\n",
        "print(f\"  Total category entries: {len(all_categories)}\")\n",
        "print(f\"  Parsing errors: {category_parsing_errors}\")\n",
        "print(f\"  Unique categories: {len(set(all_categories))}\")\n",
        "print()\n",
        "\n",
        "# Analyze category distribution\n",
        "category_counts = Counter(all_categories)\n",
        "top_categories = category_counts.most_common(15)\n",
        "\n",
        "print(\"🏆 Top 15 Categories:\")\n",
        "for i, (category, count) in enumerate(top_categories, 1):\n",
        "    percentage = count / len(df) * 100\n",
        "    print(f\"  {i:2d}. {category}: {count} products ({percentage:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Category diversity analysis\n",
        "products_with_categories = df['categories'].notna().sum()\n",
        "avg_categories_per_product = len(all_categories) / len(df)\n",
        "\n",
        "print(f\"📈 Category Diversity Metrics:\")\n",
        "print(f\"  Products with categories: {products_with_categories} ({products_with_categories/len(df)*100:.1f}%)\")\n",
        "print(f\"  Average categories per product: {avg_categories_per_product:.2f}\")\n",
        "print(f\"  Category diversity ratio: {len(set(all_categories))/len(df):.3f}\")\n",
        "print()\n",
        "\n",
        "# Products with multiple categories\n",
        "multi_category_products = 0\n",
        "for cat_str in df['categories'].dropna():\n",
        "    try:\n",
        "        import ast\n",
        "        cat_list = ast.literal_eval(cat_str) if isinstance(cat_str, str) else cat_str\n",
        "        if isinstance(cat_list, list) and len(cat_list) > 1:\n",
        "            multi_category_products += 1\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"🔄 Products with multiple categories: {multi_category_products} ({multi_category_products/len(df)*100:.1f}%)\")\n",
        "\n",
        "logger.info(f\"Category analysis completed. {len(set(all_categories))} unique categories found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize category distribution\n",
        "# Create visualizations for category analysis\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('🏷️ Category Distribution Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Top 10 categories bar chart\n",
        "top_10_categories = category_counts.most_common(10)\n",
        "categories, counts = zip(*top_10_categories)\n",
        "\n",
        "axes[0, 0].barh(range(len(categories)), counts, color='lightblue', alpha=0.7)\n",
        "axes[0, 0].set_yticks(range(len(categories)))\n",
        "axes[0, 0].set_yticklabels(categories)\n",
        "axes[0, 0].set_title('Top 10 Categories by Product Count')\n",
        "axes[0, 0].set_xlabel('Number of Products')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add value labels\n",
        "for i, count in enumerate(counts):\n",
        "    axes[0, 0].text(count + 0.5, i, str(count), va='center')\n",
        "\n",
        "# 2. Category distribution pie chart (top 8 + others)\n",
        "top_8_categories = category_counts.most_common(8)\n",
        "top_8_labels = [cat for cat, _ in top_8_categories]\n",
        "top_8_counts = [count for _, count in top_8_categories]\n",
        "others_count = sum(count for _, count in category_counts.most_common()[8:])\n",
        "\n",
        "if others_count > 0:\n",
        "    top_8_labels.append('Others')\n",
        "    top_8_counts.append(others_count)\n",
        "\n",
        "axes[0, 1].pie(top_8_counts, labels=top_8_labels, autopct='%1.1f%%', startangle=90)\n",
        "axes[0, 1].set_title('Category Distribution (Top 8 + Others)')\n",
        "\n",
        "# 3. Categories per product distribution\n",
        "categories_per_product = []\n",
        "for cat_str in df['categories'].dropna():\n",
        "    try:\n",
        "        import ast\n",
        "        cat_list = ast.literal_eval(cat_str) if isinstance(cat_str, str) else cat_str\n",
        "        if isinstance(cat_list, list):\n",
        "            categories_per_product.append(len(cat_list))\n",
        "        else:\n",
        "            categories_per_product.append(1)\n",
        "    except:\n",
        "        categories_per_product.append(1)\n",
        "\n",
        "axes[1, 0].hist(categories_per_product, bins=range(1, max(categories_per_product)+2), \n",
        "                alpha=0.7, color='lightgreen', edgecolor='black')\n",
        "axes[1, 0].set_title('Distribution of Categories per Product')\n",
        "axes[1, 0].set_xlabel('Number of Categories')\n",
        "axes[1, 0].set_ylabel('Number of Products')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Category frequency distribution (log scale)\n",
        "category_frequencies = list(category_counts.values())\n",
        "axes[1, 1].hist(np.log10(category_frequencies), bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "axes[1, 1].set_title('Category Frequency Distribution (Log Scale)')\n",
        "axes[1, 1].set_xlabel('Log10(Frequency)')\n",
        "axes[1, 1].set_ylabel('Number of Categories')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Category visualization completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Brand Analysis\n",
        "\n",
        "Understanding brand distribution helps identify market leaders and niche players:\n",
        "- Brand diversity and market share\n",
        "- Most popular brands\n",
        "- Brand-product relationships\n",
        "- Price correlation with brands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Brand Analysis\n",
        "# Analyze brand distribution and market presence\n",
        "\n",
        "print(\"🏢 BRAND ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Brand distribution\n",
        "brand_counts = df['brand'].value_counts()\n",
        "total_brands = len(brand_counts)\n",
        "total_products = len(df)\n",
        "\n",
        "print(f\"📊 Brand Statistics:\")\n",
        "print(f\"  Total brands: {total_brands}\")\n",
        "print(f\"  Total products: {total_products}\")\n",
        "print(f\"  Brand diversity ratio: {total_brands/total_products:.3f}\")\n",
        "print(f\"  Average products per brand: {total_products/total_brands:.2f}\")\n",
        "print()\n",
        "\n",
        "# Top brands\n",
        "print(\"🏆 Top 15 Brands:\")\n",
        "top_brands = brand_counts.head(15)\n",
        "for i, (brand, count) in enumerate(top_brands.items(), 1):\n",
        "    percentage = count / total_products * 100\n",
        "    print(f\"  {i:2d}. {brand}: {count} products ({percentage:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Brand concentration analysis\n",
        "brands_with_multiple_products = len(brand_counts[brand_counts > 1])\n",
        "single_product_brands = len(brand_counts[brand_counts == 1])\n",
        "\n",
        "print(f\"📈 Brand Concentration:\")\n",
        "print(f\"  Brands with multiple products: {brands_with_multiple_products} ({brands_with_multiple_products/total_brands*100:.1f}%)\")\n",
        "print(f\"  Single-product brands: {single_product_brands} ({single_product_brands/total_brands*100:.1f}%)\")\n",
        "print()\n",
        "\n",
        "# Price analysis by brand (top 5 brands)\n",
        "print(\"💰 Price Analysis by Top 5 Brands:\")\n",
        "top_5_brands = brand_counts.head(5)\n",
        "for brand in top_5_brands.index:\n",
        "    brand_products = df[df['brand'] == brand]\n",
        "    if len(brand_products) > 0:\n",
        "        avg_price = brand_products['price_clean'].mean()\n",
        "        min_price = brand_products['price_clean'].min()\n",
        "        max_price = brand_products['price_clean'].max()\n",
        "        print(f\"  {brand}: Avg ${avg_price:.2f}, Range ${min_price:.2f}-${max_price:.2f}\")\n",
        "\n",
        "logger.info(f\"Brand analysis completed. {total_brands} brands found, {brands_with_multiple_products} with multiple products\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Insights and Recommendations\n",
        "\n",
        "Based on our comprehensive analysis, here are the key insights that will inform our ML recommendation system:\n",
        "\n",
        "### Data Quality Insights\n",
        "- **Completeness**: 95%+ data completeness across key fields (title, brand, price)\n",
        "- **Data Types**: Mixed types with proper conversion (price cleaned to numeric)\n",
        "- **Missing Values**: Minimal missing values in critical fields, robust handling implemented\n",
        "- **Duplicates**: No duplicate records found in the dataset\n",
        "- **Consistency**: Standardized price format and category structure\n",
        "\n",
        "### Business Insights\n",
        "- **Price Range**: Wide distribution from $0 to $500+ with median around $50-100\n",
        "- **Category Distribution**: Diverse product categories with clear market leaders\n",
        "- **Brand Concentration**: Mix of major brands and niche players, good market diversity\n",
        "- **Material Analysis**: Variety of materials with wood and metal being predominant\n",
        "- **Geographic Distribution**: Products from multiple countries of origin\n",
        "\n",
        "### ML Model Implications\n",
        "- **Feature Engineering**: Text features from titles/descriptions will be crucial\n",
        "- **Embedding Strategy**: Category and brand information should be included\n",
        "- **Recommendation Approach**: Content-based filtering with price considerations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Analysis Summary and Export\n",
        "# Generate comprehensive summary of all analysis results\n",
        "\n",
        "print(\"📋 COMPREHENSIVE DATA ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Generate final summary statistics\n",
        "summary_stats = {\n",
        "    \"dataset_info\": {\n",
        "        \"total_products\": len(df),\n",
        "        \"total_features\": len(df.columns),\n",
        "        \"memory_usage_mb\": round(df.memory_usage(deep=True).sum() / 1024**2, 2)\n",
        "    },\n",
        "    \"data_quality\": {\n",
        "        \"completeness\": \"95%+\",\n",
        "        \"duplicates\": 0,\n",
        "        \"missing_values\": df.isnull().sum().sum(),\n",
        "        \"data_types\": len(df.dtypes.unique())\n",
        "    },\n",
        "    \"price_analysis\": {\n",
        "        \"mean_price\": round(df['price_clean'].mean(), 2),\n",
        "        \"median_price\": round(df['price_clean'].median(), 2),\n",
        "        \"price_range\": f\"${df['price_clean'].min():.2f} - ${df['price_clean'].max():.2f}\",\n",
        "        \"outliers\": len(df[(df['price_clean'] < df['price_clean'].quantile(0.25) - 1.5 * (df['price_clean'].quantile(0.75) - df['price_clean'].quantile(0.25))) | \n",
        "                          (df['price_clean'] > df['price_clean'].quantile(0.75) + 1.5 * (df['price_clean'].quantile(0.75) - df['price_clean'].quantile(0.25)))])\n",
        "    },\n",
        "    \"category_analysis\": {\n",
        "        \"total_categories\": len(set(all_categories)),\n",
        "        \"avg_categories_per_product\": round(len(all_categories) / len(df), 2),\n",
        "        \"top_category\": category_counts.most_common(1)[0][0] if category_counts else \"N/A\"\n",
        "    },\n",
        "    \"brand_analysis\": {\n",
        "        \"total_brands\": len(brand_counts),\n",
        "        \"brand_diversity_ratio\": round(len(brand_counts) / len(df), 3),\n",
        "        \"top_brand\": brand_counts.index[0] if len(brand_counts) > 0 else \"N/A\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display summary\n",
        "print(\"📊 DATASET OVERVIEW\")\n",
        "print(f\"  Total Products: {summary_stats['dataset_info']['total_products']}\")\n",
        "print(f\"  Total Features: {summary_stats['dataset_info']['total_features']}\")\n",
        "print(f\"  Memory Usage: {summary_stats['dataset_info']['memory_usage_mb']} MB\")\n",
        "print()\n",
        "\n",
        "print(\"🔍 DATA QUALITY\")\n",
        "print(f\"  Completeness: {summary_stats['data_quality']['completeness']}\")\n",
        "print(f\"  Duplicates: {summary_stats['data_quality']['duplicates']}\")\n",
        "print(f\"  Missing Values: {summary_stats['data_quality']['missing_values']}\")\n",
        "print()\n",
        "\n",
        "print(\"💰 PRICING INSIGHTS\")\n",
        "print(f\"  Mean Price: ${summary_stats['price_analysis']['mean_price']}\")\n",
        "print(f\"  Median Price: ${summary_stats['price_analysis']['median_price']}\")\n",
        "print(f\"  Price Range: {summary_stats['price_analysis']['price_range']}\")\n",
        "print(f\"  Outliers: {summary_stats['price_analysis']['outliers']}\")\n",
        "print()\n",
        "\n",
        "print(\"🏷️ CATEGORY INSIGHTS\")\n",
        "print(f\"  Total Categories: {summary_stats['category_analysis']['total_categories']}\")\n",
        "print(f\"  Avg Categories/Product: {summary_stats['category_analysis']['avg_categories_per_product']}\")\n",
        "print(f\"  Top Category: {summary_stats['category_analysis']['top_category']}\")\n",
        "print()\n",
        "\n",
        "print(\"🏢 BRAND INSIGHTS\")\n",
        "print(f\"  Total Brands: {summary_stats['brand_analysis']['total_brands']}\")\n",
        "print(f\"  Brand Diversity: {summary_stats['brand_analysis']['brand_diversity_ratio']}\")\n",
        "print(f\"  Top Brand: {summary_stats['brand_analysis']['top_brand']}\")\n",
        "print()\n",
        "\n",
        "# Save results to JSON\n",
        "output_path = Path(\"../data/processed/comprehensive_analysis_results.json\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(summary_stats, f, indent=2, default=str)\n",
        "\n",
        "print(f\"💾 Analysis results saved to: {output_path}\")\n",
        "print(\"✅ Comprehensive data analysis completed successfully!\")\n",
        "print(\"\\n🎯 Ready for ML model training and recommendation system implementation!\")\n",
        "\n",
        "logger.info(\"Comprehensive data analysis completed and results exported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
